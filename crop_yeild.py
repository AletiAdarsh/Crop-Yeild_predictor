# -*- coding: utf-8 -*-
"""Crop_yeild.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16AT6KVmpkVTPgNeFL10mXH0P0gN1XJHM
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
pd.set_option("display.max_columns", None)

print("Loading Dataset")
crop_yeild=pd.read_csv('/content/drive/MyDrive/crop_yield.csv')
print("\ncrop_yeild Dataset has been Loaded Successfully")

crop_yeild.isnull().sum()

import matplotlib.pyplot as plt
import seaborn as sns

def exploredata(df, name, target=None, sample_n_pairplot=500):
    print(f"\nüîç Exploring Dataset: {name}")
    print("-" * 60)

    # 1. Shape, Types, Head
    print(f"\nüìê Shape: {df.shape[0]} rows √ó {df.shape[1]} cols")
    print("\nüî£ Data types:")
    print(df.dtypes)
    print("\nüëÄ First 5 rows:")
    display(df.head())
    print("\n‚ÑπÔ∏è Info:")
    df.info(memory_usage='deep')

    # 2. Descriptive stats
    print("\nüìä Descriptive statistics (all cols):")
    display(df.describe(include='all').T)

    # 3. Missing values
    mv = df.isnull().sum()
    mv_pct = (mv / len(df) * 100).loc[lambda x: x > 0]
    if mv_pct.empty:
        print("\n‚úÖ No missing values.")
    else:
        print("\n‚ö†Ô∏è Missing values (%):")
        print(mv_pct)
        plt.figure(figsize=(10,4))
        sns.barplot(x=mv_pct.index, y=mv_pct.values)
        plt.xticks(rotation=90)
        plt.ylabel("% missing")
        plt.title(f"{name} ‚Äì Missing Data")
        plt.tight_layout()
        plt.show()
        plt.figure(figsize=(12,6))
        sns.heatmap(df.isnull(), cbar=False)
        plt.title(f"{name} ‚Äì Missing-Value Map")
        plt.show()

    # Distribution of numerical features
    df.hist(figsize=(20, 20), bins=30)
    plt.suptitle(f"Numerical Feature Distributions - {name}", fontsize=14)
    plt.show()

exploredata(crop_yeild,"Crop_Yeild")

def analyze_variable_types(df, name):
    """
    Analyzes the types of variables in the dataset.
    - Counts numerical, categorical, and other types of variables.
    """
    print(f"\nüîç Analyzing Variable Types in {name}")
    print("-" * 50)

    var_types = df.dtypes.value_counts()
    print(df.dtypes)
    print(var_types)

    # Plot distribution of variable types
    plt.figure(figsize=(8, 5))
    var_types.plot(kind='bar', color='skyblue', edgecolor='black')
    plt.title(f"Variable Type Distribution in {name}")
    plt.xlabel("Data Type")
    plt.ylabel("Count")
    plt.xticks(rotation=45)
    plt.show()

# Run analysis on datasets
analyze_variable_types(crop_yeild, "Crop Yeild")

crop_yeild.columns

crop_yeild.head(3)

def remove_outliers_iqr(df, cols):
    df_clean = df.copy()
    for col in cols:
        Q1 = df_clean[col].quantile(0.25)
        Q3 = df_clean[col].quantile(0.75)
        IQR = Q3 - Q1
        lower, upper = Q1 - 1.5 * IQR, Q3 + 1.5 * IQR

        # Count outliers for this column
        outliers = df_clean[(df_clean[col] < lower) | (df_clean[col] > upper)]
        print(f"{col}: {len(outliers)} outliers detected")

        # Drop rows outside the bounds
        df_clean = df_clean[(df_clean[col] >= lower) & (df_clean[col] <= upper)]
    return df_clean

num_cols = crop_yeild.select_dtypes(include=[np.number]).columns
print("Numeric columns:", list(num_cols))

remove_outliers_iqr(crop_yeild,num_cols)

print("\nConverting Boolean cols to 1 or 0 type ")
crop_yeild['Fertilizer_Used']   = crop_yeild['Fertilizer_Used'].astype(int)
crop_yeild['Irrigation_Used']   = crop_yeild['Irrigation_Used'].astype(int)
print("\nDONE")
print("\nConverting catogerical Columns to Numerical using One Hot Encoder")
crop_yeild=pd.get_dummies(crop_yeild,columns=['Region','Soil_Type','Crop','Weather_Condition'],drop_first=True)
print("\nDONE")

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
num_cols = ['Rainfall_mm','Temperature_Celsius','Days_to_Harvest']
crop_yeild[num_cols] = scaler.fit_transform(crop_yeild[num_cols])

from sklearn.model_selection import train_test_split

X = crop_yeild.drop('Yield_tons_per_hectare', axis=1)
y = crop_yeild['Yield_tons_per_hectare']

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

from sklearn.linear_model import LinearRegression
from xgboost import XGBRegressor
from sklearn.metrics import mean_squared_error, r2_score

lr = LinearRegression()
lr.fit(X_train, y_train)

xgb_model = XGBRegressor(random_state=42, n_jobs=-1)
xgb_model.fit(X_train, y_train)

from sklearn.metrics import mean_squared_error, r2_score
import numpy as np

# Predict
lr_y_pred = lr.predict(X_test)
xgb_y_pred=xgb_model.predict(X_test)

# Compute MSE, then RMSE
lr_mse  = mean_squared_error(y_test,lr_y_pred)
lr_rmse = np.sqrt(lr_mse)

# Compute R¬≤
lr_r2   = r2_score(y_test,lr_y_pred)

Xgb_mse  = mean_squared_error(y_test,xgb_y_pred)
Xgb_rmse = np.sqrt(Xgb_mse)

# Compute R¬≤
Xgb_r2   = r2_score(y_test,xgb_y_pred)
print(f"Linear Regression ‚Üí RMSE: {lr_rmse:.3f}, R¬≤: {lr_r2:.3f}")
print(f"XgBoost ‚Üí RMSE: {Xgb_rmse:.3f}, R¬≤: {Xgb_r2:.3f}")

from sklearn.model_selection import RandomizedSearchCV, KFold

# Define 5-fold cross-validation
cv = KFold(n_splits=5, shuffle=True, random_state=42)

# Define models and hyperparameter grids
models = {
    "XGBoost": {
        "model": XGBRegressor(n_jobs=4, random_state=42),
        "param_grid": {
            'n_estimators': [100, 200],
            'max_depth': [3, 6],
            'learning_rate': [0.01, 0.1],
            'subsample': [0.8, 1.0]
    }
},
    "LinearRegression": {
        "model": LinearRegression(),
        "param_grid": {
            'fit_intercept': [True, False],
            'copy_X': [True, False]
        }
    }
}

# Run Randomized Search for each model
best_params = {}
best_models = {}
for model_name, model_info in models.items():
    print(f"üîç Running RandomizedSearchCV for {model_name}...")
    RS = RandomizedSearchCV(
        model_info["model"], model_info["param_grid"], n_iter=8, cv=cv,
        scoring='neg_mean_absolute_error', n_jobs=4, random_state=42, verbose=2
    )
    RS.fit(X, y)
    best_params[model_name] = RS.best_params_
    best_models[model_name] = RS.best_estimator_
    print(f"‚úÖ Best {model_name} Parameters: {RS.best_params_}")

from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import numpy as np

# Pick your best estimator, e.g. the tuned XGBoost:
best_xgb = best_models["XGBoost"]

# Generate predictions
y_test_pred = best_xgb.predict(X_test)

# Compute metrics
mae  = mean_absolute_error(y_test, y_test_pred)
rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))
r2   = r2_score(y_test, y_test_pred)

print(f"‚úîÔ∏è Test MAE:  {mae:.3f}")
print(f"‚úîÔ∏è Test RMSE: {rmse:.3f}")
print(f"‚úîÔ∏è Test R¬≤:   {r2:.3f}")

pred_xgb = best_models["XGBoost"].predict(X_test)
pred_lr  = best_models["LinearRegression"].predict(X_test)

ensemble_pred = 0.7 * pred_xgb + 0.3 * pred_lr  # weights chosen by CV performance

ensemble_rmse = np.sqrt(mean_squared_error(y_test, ensemble_pred))
print(f"Ensemble RMSE: {ensemble_rmse:.3f}")

import matplotlib.pyplot as plt

# Predictions from your best model (e.g. XGBoost)
y_pred = best_models["XGBoost"].predict(X_test)
residuals = y_test - y_pred

# 1a. Residual vs. Predicted
plt.scatter(y_pred, residuals, alpha=0.3)
plt.hlines(0, y_pred.min(), y_pred.max(), colors='red', linestyles='dashed')
plt.xlabel("Predicted Yield (t/ha)")
plt.ylabel("Residual (Actual ‚àí Predicted)")
plt.title("Residuals vs. Predicted")
plt.show()

# 1b. Residual Distribution
plt.hist(residuals, bins=30, edgecolor='k')
plt.title("Histogram of Residuals")
plt.xlabel("Residual")
plt.ylabel("Frequency")
plt.show()